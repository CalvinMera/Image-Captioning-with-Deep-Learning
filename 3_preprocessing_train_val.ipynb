{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "annotations_intermediate_path = '/data/annotations/'\n",
    "annotations_ending_path = {'train':'train.json', 'val':'val.json'}\n",
    "images_intermediate_path = {'train':'/data/images/train/', 'val':'/data/images/val/'}\n",
    "\n",
    "# Creating a function to prepare the training and validation data.\n",
    "\n",
    "def prepare (dataset, create = False):\n",
    "# Dataset is either training or validation.\n",
    "# The create option will dictate if .json file is created. These files have already been created so we set\n",
    "# create equal to a default value of False.\n",
    "    with open(os.path.abspath('.') + annotations_intermediate_path + annotations_ending_path[dataset], 'r') as f:\n",
    "        data = json.load(f)\n",
    "    directory = os.path.abspath('.') + annotations_intermediate_path + annotations_ending_path[dataset]\n",
    "\n",
    "# The 2 data frames of interest.\n",
    "    images_df = pd.DataFrame(data['images'])\n",
    "    annotations_df = pd.DataFrame(data['annotations'])\n",
    "\n",
    "# Images are indexed by image_id (number of unique values for image_id coincides with the number of training images).\n",
    "# Captions are indexed by id (number of unique values for id coincides with the number of training captions).\n",
    "\n",
    "# If is_precanned is True, then the associated caption is: 'Quality issues are too severe to recognize visual content.'\n",
    "# If is_rejected is True, then the associated caption is spam. See peeking_into_train.ipynb for examples.\n",
    "# If text_detected is True, then the image contains text.\n",
    "\n",
    "# A richer analysis would involve an examination of text_detected. We do not pursue this.\n",
    "\n",
    "# Preparing the images data frame for a join.\n",
    "    images_df.drop(['vizwiz_url', 'text_detected'], axis = 1, inplace = True)\n",
    "\n",
    "# This is added in order to account for how the data sets are enumerated. This applies to val, not to train.\n",
    "    images_df['id'] = images_df['id']-images_df['id'][0] \n",
    "    images_df.columns = ['file_name', 'image_id']\n",
    "\n",
    "# Preparing the annotations data frame for a join.\n",
    "    annotations_df.drop(['text_detected'], axis =1,inplace=True )\n",
    "\n",
    "# This is added in order to account for how the data sets are enumerated. This applies to val, not to train.\n",
    "    annotations_df['image_id'] = annotations_df['image_id'] - annotations_df['image_id'][0]\n",
    "    annotations_df['id'] = annotations_df['id']- annotations_df['id'][0]\n",
    "    annotations_df.columns = ['caption', 'image_id', 'is_precanned', 'is_rejected', 'caption_id']\n",
    "\n",
    "# We now join the data frames.\n",
    "    joined_df = annotations_df.join(images_df, on = 'image_id', how = 'left', lsuffix='', rsuffix = '_img')\n",
    "    joined_df.drop(['image_id_img'], axis = 1, inplace = True)\n",
    "\n",
    "# From this newly formed dataframe, we construct several dataframes in order to shed light on the relationship between\n",
    "# images, captions, is_precanned, and is_rejected.\n",
    "\n",
    "# 1. The number of images having n precanned captions, where n ranges from 0 to 5.\n",
    "    df1 = annotations_df.groupby('image_id').agg({'is_precanned':'sum'}).value_counts(sort=False).to_frame()\n",
    "    df1.columns = ['number_of_images']\n",
    "    df1['number_of_precanned_captions'] = [n for n in range(list(df1.index)[0][0],list(df1.index)[-1][0]+1)]\n",
    "    df1 = df1.rename_axis('Index')\n",
    "    print(df1)\n",
    "\n",
    "    df1_columns = list(df1.columns)\n",
    "    df1.plot.bar(x= df1_columns[1], xlabel = df1_columns[1], y = df1_columns[0], ylabel = df1_columns[0],\n",
    "    rot=0, legend = None, title = 'Number of images with n precanned captions')\n",
    "\n",
    "# 2. The number of captions that are precanned.\n",
    "    df2 = annotations_df.groupby('caption_id').agg({'is_precanned':'sum'}).value_counts(sort=False).to_frame()\n",
    "    df2.columns = ['number_of_captions']\n",
    "    df2['is_precanned'] = [n for n in range(list(df2.index)[0][0],list(df2.index)[-1][0]+1)]\n",
    "    df2 = df2.rename_axis('Index')\n",
    "    print(df2)\n",
    "\n",
    "    df2_columns = list(df2.columns)\n",
    "    df2.plot.bar(x= df2_columns[1], xlabel = df2_columns[1], y = df2_columns[0], ylabel = df2_columns[0],\n",
    "    rot=0, legend = None, title = 'Number of precanned captions')\n",
    "\n",
    "# 3. The number of images having n rejected captions, where n ranges from 0 to 5.\n",
    "    df3 = annotations_df.groupby('image_id').agg({'is_rejected':'sum'}).value_counts(sort=False).to_frame()\n",
    "    df3.columns = ['number_of_images']\n",
    "    df3['number_of_rejected_captions'] = [n for n in range(list(df3.index)[0][0],list(df3.index)[-1][0]+1)]\n",
    "    df3 = df3.rename_axis('Index')\n",
    "    print(df3)\n",
    "\n",
    "    df3_columns = list(df3.columns)\n",
    "    df3.plot.bar(x= df3_columns[1], xlabel = df3_columns[1], y = df3_columns[0], ylabel = df3_columns[0],\n",
    "    rot=0, legend = None, title = 'Number of images with n rejected captions')\n",
    "\n",
    "# 4. The number of captions that are rejected.\n",
    "    df4 = annotations_df.groupby('caption_id').agg({'is_rejected':'sum'}).value_counts(sort=False).to_frame()\n",
    "    df4.columns = ['number_of_captions']\n",
    "    df4['is_rejected'] = [n for n in range(list(df4.index)[0][0],list(df4.index)[-1][0]+1)]\n",
    "    df4 = df4.rename_axis('Index')\n",
    "    print(df4)\n",
    "\n",
    "    df4_columns = list(df4.columns)\n",
    "    df4.plot.bar(x= df4_columns[1], xlabel = df4_columns[1], y = df4_columns[0], ylabel = df4_columns[0],\n",
    "    rot=0, legend = None, title = 'Number of rejected captions')\n",
    "\n",
    "# Before we tackle data frames 5 and 6, we need to form a new dataframe.\n",
    "    pre_df56 = annotations_df[(annotations_df.is_rejected == True) & (annotations_df.is_precanned == True)]\n",
    "\n",
    "# 5. The number of images that have n precanned and rejected captions.\n",
    "    df5 = pre_df56.groupby('image_id').agg({'is_precanned':'sum'}).value_counts(sort=False).to_frame()\n",
    "    df5.columns = ['number_of_images']\n",
    "    df5['is_rejected_and_precanned'] = [n for n in range(list(df5.index)[0][0],list(df5.index)[-1][0]+1)]\n",
    "    df5 =df5.rename_axis('Index')\n",
    "    print(df5)\n",
    "\n",
    "    df5_columns = list(df5.columns)\n",
    "    df5.plot.bar(x= df5_columns[1], xlabel = df5_columns[1], y = df5_columns[0], ylabel = df5_columns[0],\n",
    "    rot=0, legend = None, title = 'Number of images with n rejected and precanned captions')\n",
    "\n",
    "# 6. The number of captions that are precanned and rejected.\n",
    "    df6 = pre_df56.groupby('caption_id').agg({'is_precanned':'sum'}).value_counts(sort=False).to_frame()\n",
    "    df6.columns = ['number_of_captions']\n",
    "    df6['is_rejected_and_precanned'] = [n for n in range(list(df6.index)[0][0],list(df6.index)[-1][0]+1)]\n",
    "    df6 = df6.rename_axis('Index')\n",
    "    print(df6)\n",
    "\n",
    "    df6_columns = list(df6.columns)\n",
    "    df6.plot.bar(x= df6_columns[1], xlabel = df6_columns[1], y = df6_columns[0], ylabel = df6_columns[0],\n",
    "    rot=0, legend = None, title = 'Number of rejected and precanned captions')\n",
    "\n",
    "# Annotations summary\n",
    "    print(f'There are {joined_df.image_id.nunique()} {dataset} images.')\n",
    "    print(f'There are {joined_df.caption_id.nunique()} {dataset} captions.')\n",
    "    print('')\n",
    "    print(f'{df1.number_of_images.sum()-df1.number_of_images.iloc[0]} {dataset} images have precanned captions.')\n",
    "    print(f'{df2.number_of_captions.iloc[1]} {dataset} captions are precanned.')\n",
    "    print('')\n",
    "    print(f'{df3.number_of_images.sum()-df3.number_of_images.iloc[0]} {dataset} images have rejected captions.')\n",
    "    print(f'{df4.number_of_captions.iloc[1]} {dataset} captions are rejected.')\n",
    "    print('')\n",
    "    print(f'{df5.number_of_images.sum()} {dataset} images have precanned and rejected captions.')\n",
    "    print(f'{df6.number_of_captions.iloc[0]} {dataset} captions are precanned and rejected.')\n",
    "\n",
    "# Dropping all rejected captions.\n",
    "    index_rejected = joined_df[joined_df.is_rejected == True].index\n",
    "    joined_df.drop(index_rejected, inplace = True)\n",
    "\n",
    "# For the training data, we provide the following insight. For more details see peeking_into_train.ipynb.\n",
    "# The total number of unique training images will not decrease because there are no images with 5 rejected captions.\n",
    "\n",
    "# Dropping the is_rejected column.\n",
    "    joined_df.drop(['is_rejected'], axis = 1, inplace = True)\n",
    "\n",
    "# Dropping all precanned captions.\n",
    "    index_precanned = joined_df[joined_df.is_precanned == True].index\n",
    "    joined_df.drop(index_precanned, inplace = True)\n",
    "\n",
    "    # print(joined_df.nunique()) This was used in order to check that the number of captions left over after the removal of\n",
    "    # precanned captions and rejected captions is equal to: total - precanned - rejected + precanned/rejected = 100575.\n",
    "\n",
    "# For the training data, we provide the following insight. For more details see peeking_into_train.ipynb. \n",
    "# The total number of unique images will decrease here because there are images whose captions might be solely composed of\n",
    "# precanned and rejected captions, so upon dropping these unwanted captions we end up dropping the associated images from the data frame.\n",
    "    joined_df.drop(['is_precanned'], axis = 1, inplace = True)\n",
    "\n",
    "# For our analysis, we only keep images that have at least 3 captions.\n",
    "# First, we construct a data frame where each row is some image id and the number of captions it has.\n",
    "    captions_df = joined_df.groupby('image_id').caption_id.count().to_frame()\n",
    "\n",
    "# Then, we create a column, which inherits the index of the dataframe because the index is equal to image_id.\n",
    "    captions_df['image_id']=captions_df.index\n",
    "    captions_df = captions_df.rename_axis('Index')\n",
    "    captions_df.columns = ['number_of_captions', 'image_id']\n",
    "\n",
    "# Now we create a dictionary whose keys are some number of captions, n (0-5) and whose values are the images that have n captions.\n",
    "    captions_to_image_id = {}\n",
    "    for number in range(6):\n",
    "        mask = captions_df.number_of_captions ==  number\n",
    "        image_id = list(captions_df[mask].image_id)\n",
    "        captions_to_image_id [number] = image_id\n",
    "\n",
    "# We only care about images that have less than 3 captions, so we join them into a list.\n",
    "    images_to_drop = captions_to_image_id[1] + captions_to_image_id[2]\n",
    "\n",
    "# Now we create a dictionary whose keys are image_id and whose values are the indices of the data frame.\n",
    "    image_id_to_index = collections.defaultdict(list)\n",
    "    for row in range(joined_df.shape[0]):\n",
    "        image_id = joined_df.image_id.iloc[row]\n",
    "        df_index = joined_df.iloc[row].name\n",
    "        image_id_to_index[image_id].append(df_index)\n",
    "\n",
    "# We are now ready to drop the images that has less than 3 captions.\n",
    "    for image_id in images_to_drop:\n",
    "        indices = image_id_to_index[image_id]\n",
    "        joined_df.drop(indices, inplace =True)\n",
    "# We print the number of unique values as a quick check, namely, the number of images coincides with the number of file names.\n",
    "    print(joined_df.nunique())\n",
    "    print(joined_df)\n",
    "# We now convert this processed data frame into a .json file.\n",
    "    # if create == True:\n",
    "    #     json_file = joined_df.to_json(orient = 'index')\n",
    "    #     with open (dataset + '_cleaned.json', 'w') as g:\n",
    "    #         g.write(json_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "prepare('train')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prepare('val')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56391efcfd407cdfb7177f7052d9ec0dabb31d2434d8abe883c176e68133b969"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('mlp_1_env': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}